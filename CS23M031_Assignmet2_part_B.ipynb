{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30673,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from random import shuffle\n",
        "import wandb\n",
        "import numpy as np\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import SubsetRandomSampler\n",
        "import torchvision"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-08T05:23:19.795740Z",
          "iopub.execute_input": "2024-04-08T05:23:19.796032Z",
          "iopub.status.idle": "2024-04-08T05:23:26.990567Z",
          "shell.execute_reply.started": "2024-04-08T05:23:19.795999Z",
          "shell.execute_reply": "2024-04-08T05:23:26.989798Z"
        },
        "trusted": true,
        "id": "tK8Utg2u6Bu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/wandb_datasets/nature_12K.zip -O nature_12K.zip\n",
        "!unzip -q nature_12K.zip"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-08T05:23:26.992478Z",
          "iopub.execute_input": "2024-04-08T05:23:26.992876Z",
          "iopub.status.idle": "2024-04-08T05:24:14.867190Z",
          "shell.execute_reply.started": "2024-04-08T05:23:26.992841Z",
          "shell.execute_reply": "2024-04-08T05:24:14.865432Z"
        },
        "trusted": true,
        "id": "tuSw4MGt6Bu3",
        "outputId": "52aede11-38a8-403a-df46-77104d896325"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "--2024-04-08 05:23:27--  https://storage.googleapis.com/wandb_datasets/nature_12K.zip\nResolving storage.googleapis.com (storage.googleapis.com)... 173.194.217.207, 173.194.210.207, 173.194.211.207, ...\nConnecting to storage.googleapis.com (storage.googleapis.com)|173.194.217.207|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3816687935 (3.6G) [application/zip]\nSaving to: 'nature_12K.zip'\n\nnature_12K.zip      100%[===================>]   3.55G   200MB/s    in 18s     \n\n2024-04-08 05:23:46 (198 MB/s) - 'nature_12K.zip' saved [3816687935/3816687935]\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "gcdKGnvS6Bu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "7jkFATnp6Bu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IqFJXq9C6Bu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "lNLp7IXq6Bu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "joDaftoX6Bu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "SqGQad236Bu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import SubsetRandomSampler\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train(model, train_loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total_predictions += labels.size(0)\n",
        "        correct_predictions += (predicted == labels).sum().item()\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    epoch_accuracy = correct_predictions / total_predictions\n",
        "    return epoch_loss, epoch_accuracy\n",
        "\n",
        "\n",
        "def evaluate(model, data_loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in data_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_predictions += labels.size(0)\n",
        "            correct_predictions += (predicted == labels).sum().item()\n",
        "    loss = running_loss / len(data_loader.dataset)\n",
        "    accuracy = correct_predictions / total_predictions\n",
        "    return loss, accuracy\n",
        "\n",
        "\n",
        "def fit_model(img_size, n_filters, filter_size, fc_size, drop_out, n_classes, learning_rate, num_epochs,\n",
        "              activation, optimizer_type):\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((img_size, img_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    train_data_path = \"/kaggle/working/inaturalist_12K/train\"\n",
        "    test_data_path = \"/kaggle/working/inaturalist_12K/val\"\n",
        "    train_dataset = datasets.ImageFolder(train_data_path, transform=transform)\n",
        "    val_size = int(0.1 * len(train_dataset))\n",
        "    class_indices = {class_idx: [] for class_idx in range(len(train_dataset.classes))}\n",
        "    for idx, (_, label) in enumerate(train_dataset):\n",
        "        class_indices[label].append(idx)\n",
        "    val_indices = []\n",
        "    for class_idx, indices in class_indices.items():\n",
        "        val_indices.extend(indices[:val_size // len(train_dataset.classes)])\n",
        "    val_sampler = SubsetRandomSampler(val_indices)\n",
        "    batch_size = 512\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=val_sampler)\n",
        "\n",
        "    model = models.resnet50(pretrained=True)\n",
        "    for param in model.parameters():\n",
        "      param.requires_grad=False\n",
        "\n",
        "    num_features=model.fc.in_features\n",
        "    model.fc=nn.Linear(num_features,10)\n",
        "\n",
        "    if optimizer_type == 'adam':\n",
        "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    elif optimizer_type == 'nadam':\n",
        "        optimizer = optim.NAdam(model.parameters(), lr=learning_rate)\n",
        "    elif optimizer_type == 'rmsprop':\n",
        "        optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss, accuracy = train(model, train_loader, criterion, optimizer, device)\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {accuracy:.4f}\")\n",
        "        wandb.log({\"train_loss\":train_loss,\"train_acc\":accuracy,\"Epoch\":epoch})\n",
        "\n",
        "        val_loss, val_accuracy = evaluate(model, val_loader, criterion, device)\n",
        "        print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
        "        wandb.log({\"Val_loss\":val_loss,\"Val_acc\":val_accuracy})\n",
        "\n",
        "    test_dataset = datasets.ImageFolder(test_data_path, transform=transform)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loss, test_accuracy = evaluate(model, test_loader, criterion, device)\n",
        "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "img_size = 224\n",
        "n_filters = [16, 32, 64, 128, 256]\n",
        "filter_size = [3, 3, 3, 3, 3]\n",
        "fc_size = 512\n",
        "drop_out = 0.5\n",
        "n_classes = 10\n",
        "learning_rate = 0.0001\n",
        "num_epochs = 10\n",
        "activation = 'relu'\n",
        "optimizer_type = 'adam'\n",
        "\n",
        "# Fit the model\n",
        "trained_model = fit_model(img_size, n_filters, filter_size, fc_size, drop_out, n_classes, learning_rate, num_epochs,\n",
        "                     activation, optimizer_type)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-08T05:25:57.307122Z",
          "iopub.execute_input": "2024-04-08T05:25:57.307422Z"
        },
        "trusted": true,
        "id": "G6l2XJ-C6Bu4",
        "outputId": "5f10a2c3-2027-4c0f-9aef-ca8f939d60f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/10, Train Loss: 2.2214, Train Accuracy: 0.2256\nValidation Loss: 0.2274, Validation Accuracy: 0.1141\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main(args):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n",
        "\n",
        "\n",
        "    # Set up WandB\n",
        "    if not args.no_wandb:\n",
        "        wandb.init(project=\"CS6910_ass2\", entity=\"joel-raj2017\")\n",
        "\n",
        "    # Model hyperparameters\n",
        "    img_size = args.img_size\n",
        "    n_filters = args.n_filters\n",
        "    filter_size = args.filter_size\n",
        "    fc_size = args.fc_size\n",
        "    drop_out = args.drop_out\n",
        "    n_classes = args.n_classes\n",
        "    learning_rate = args.learning_rate\n",
        "    num_epochs = args.num_epochs\n",
        "    activation = args.activation\n",
        "    optimizer_type = args.optimizer_type\n",
        "\n",
        "    # Fit the model\n",
        "    trained_model = fit_model(img_size, n_filters, filter_size, fc_size, drop_out, n_classes, learning_rate, num_epochs,\n",
        "                              activation, optimizer_type, device)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser(description=\"Train CNN model for classification\")\n",
        "    parser.add_argument(\"--img_size\", type=int, default=224, help=\"Input image size\")\n",
        "    parser.add_argument(\"--n_filters\", nargs=\"+\", type=int, default=[16, 32, 64, 128, 256], help=\"Number of filters in each convolutional layer\")\n",
        "    parser.add_argument(\"--filter_size\", nargs=\"+\", type=int, default=[3, 3, 3, 3, 3], help=\"Size of filters in each convolutional layer\")\n",
        "    parser.add_argument(\"--fc_size\", type=int, default=512, help=\"Size of the fully connected layer\")\n",
        "    parser.add_argument(\"--drop_out\", type=float, default=0.5, help=\"Dropout probability\")\n",
        "    parser.add_argument(\"--n_classes\", type=int, default=10, help=\"Number of output classes\")\n",
        "    parser.add_argument(\"--learning_rate\", type=float, default=0.0001, help=\"Learning rate\")\n",
        "    parser.add_argument(\"--num_epochs\", type=int, default=10, help=\"Number of epochs\")\n",
        "    parser.add_argument(\"--activation\", choices=[\"relu\", \"elu\", \"silu\", \"selu\", \"gelu\"], default=\"relu\", help=\"Activation function\")\n",
        "    parser.add_argument(\"--optimizer_type\", choices=[\"adam\", \"nadam\", \"rmsprop\"], default=\"adam\", help=\"Optimizer type\")\n",
        "    parser.add_argument(\"--no_cuda\", action=\"store_true\", help=\"Disable CUDA\")\n",
        "    parser.add_argument(\"--no_wandb\", action=\"store_true\", help=\"Disable WandB logging\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    main(args)"
      ],
      "metadata": {
        "trusted": true,
        "id": "53NAnzeA6Bu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-08T05:13:00.715681Z",
          "iopub.execute_input": "2024-04-08T05:13:00.716362Z",
          "iopub.status.idle": "2024-04-08T05:13:20.203465Z",
          "shell.execute_reply.started": "2024-04-08T05:13:00.716332Z",
          "shell.execute_reply": "2024-04-08T05:13:20.202460Z"
        },
        "trusted": true,
        "id": "vHNtuPJ96Bu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "OJ3oS2Wv6Bu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4_yXonQu6Bu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IY1aL3XY6Bu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "Kky9F0x-6Bu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aKVrLhop6Bu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I5E1H4Kd6Bu6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}